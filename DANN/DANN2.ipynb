{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Domain-Adversarial Training of Neural Networks (DANN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import RandomSampler,Dataset,DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer,epoch):\n",
    "    lr=0.001*0.1**(epoch//10)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr\n",
    "    return lr\n",
    "\n",
    "def accuracy(output,target,topk=(1,)):\n",
    "    maxk=max(topk)\n",
    "    batch_size=target.size(0)\n",
    "    _,pred=output.topk(maxk,1,True,True)\n",
    "    pred=pred.t()\n",
    "    correct=pred.eq(target.view(1,-1).expand_as(pred))\n",
    "    res=[]\n",
    "    for k in topk:\n",
    "        correct_k=correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100/batch_size))\n",
    "    return res\n",
    "\n",
    "def matplotlib_imshow(img,one_channel=False):\n",
    "    if one_channel:\n",
    "        img=img.mean(dim=0)\n",
    "    np_img=img.numpy()\n",
    "    np_img=(np_img-np.min(np_img))/(np.max(np_img)-np.min(np_img))\n",
    "    if one_channel:\n",
    "        plt.imshow(np_img,cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(np_img,(1,2,0)))\n",
    "\n",
    "class ColoredMNIST(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.data_label = torch.load(file_name)\n",
    "        # self.data_label=transforms.ToTensor()(self.data_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data_label[index]\n",
    "        img = transforms.ToTensor()(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_label)\n",
    "\n",
    "    def __add__(self,other):\n",
    "        pass\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val=0\n",
    "        self.avg=0\n",
    "        self.sum=0\n",
    "        self.count=0\n",
    "    def update(self,val,n=1):\n",
    "        self.val=val\n",
    "        self.sum+=val*n\n",
    "        self.count+=n\n",
    "        self.avg=self.sum/self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_dir=\"minist_experiment_1\"\n",
    "remove_log_dir=True\n",
    "if remove_log_dir and os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_size=28\n",
    "batch_size=32\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.5],std=[0.5])])\n",
    "train_ds = ColoredMNIST('./dataset/ColoredMNIST/train1.pt') # source domain training datasets\n",
    "train_dl = data.DataLoader(dataset=train_ds,batch_size=batch_size,shuffle=True)\n",
    "test_ds = ColoredMNIST('./dataset/ColoredMNIST/train2.pt') # source domain testing datasets\n",
    "test_dl = data.DataLoader(dataset=test_ds,batch_size=batch_size,shuffle=False)\n",
    "train_m_ds = ColoredMNIST('./dataset/ColoredMNIST/test.pt') # target domain training datasets\n",
    "train_m_dl = data.DataLoader(dataset=train_m_ds,batch_size=batch_size,shuffle=True)\n",
    "test_m_ds = ColoredMNIST('./dataset/ColoredMNIST/test.pt') # target domain testing datasets\n",
    "test_m_dl = data.DataLoader(dataset=test_m_ds,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "writer=SummaryWriter(log_dir)\n",
    "show_images=[train_ds[i][0] for i in range(8)]\n",
    "show_labels=[train_ds[i][1] for i in range(8)]\n",
    "show_img_grid=make_grid(show_images)\n",
    "matplotlib_imshow(show_img_grid,one_channel=True)\n",
    "writer.add_image(\"mnist_images\",show_img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABOCAYAAAA5Hk1WAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaZklEQVR4nO2de3BdxX3HP6trvZBlS35iyzY2xoAwIWAcE4cUPEmMIQ9MJi9aQsiUhE5Ips1M2ombtAnT6WTSTpJpJpNmSlqax6ShNEkT0iYhBAgkBBtjLJBtYWwexg9ZsvEDP2U9tn98d3vuvbpXkqV7zrmXu5+ZO1c6utJZ7dn97u/329/uGmstgUAgEKg8atIuQCAQCATGRxDwQCAQqFCCgAcCgUCFEgQ8EAgEKpQg4IFAIFChBAEPBAKBCmVCAm6Mud4Ys90Ys9MYs65UhQoEAoHA6Jjx5oEbYzLA88BqYA+wEfhja+220hUvEAgEAsWYiAW+AthprX3RWnsGuBdYW5piBQKBQGA0Jk3gd9uA3Vnf7wGuyv+QMeYO4A737ZUTuF8gEAhUKwettTPzL05EwE2Ba8PiMdbau4G7AYwxYd1+IBAInD27Cl2cSAhlDzA/6/t5wL4J/L1AIBAInAUTEfCNwBJjzCJjTB1wM3B/aYoVCAQCgdEYdwjFWjtgjPkU8ACQAe6x1m4tWckCgUAgMCLjTiMc181CDDwQCATGwyZr7fL8i2ElZiAQCFQoE8lCCQTKg1rgQuA9wDTgMPA94FXgdIrl8mSAO4EZwDHgO6iMgymWyVMDNAFvQCkJbcACohwzg3LLXgC2Ab9JoYwVSCMwE/go0ADsBb4Zw32CgAeEQUJ4DurUxn3dB5xx76cpkCiaMpOAKcBK1Fvmod7yLLADOAAcIb1yTwJagD8BzkN5Wj8DXiNdAZ9M9LznA28HLgEuRmJuiETcApuAR5GQ70PtIVCUacAy4HY0PnYA/wIMlPg+QcADog44H7gGCWIt8A7U8rYDW1HeUbl13NnAFcCXULknof/j68BTwB/QKoQ+0hHxOcAqJI5NwFEk6HtSKIsngzbAWARcBLwP1V1+QDW7vq4AlgLvQoNRR+ylrGjeAvwTMAvoR1Z4G7ItSiniQcADEupV7jULibcBpqLQxEkkPK8CvwMeBp5IoZyFqEPWZDNqzd5qnAMsQRZ4A/Ii0hDwGcCbUZ2CLN4rgZ3AqRTKcwGwBpmGU1x5mom8rkGgG+hFSjMVDYiTiLydTDxFuxwt5b4177qP4uDefwn8FthMOlU4FuqB6USO7WzgRuD7yCEsFZUv4NnrQX08byZqlOegjpxBDfMossqOkmhnbkM6cxo4hAywZlT0Jve9XyO7DY3SR5IoWA1wKfBHSLzbkaV6BDjovm5zBWxFgujFfS/QQ7oWeTMSpCuzyuWpRwPPYUrvt44V/4Dno7o+hurMi2PS1KP49juQ5V1HJNpdKKxzHK352+euz0JKNBX9D9mDZIkwKLq0DFmuKwv8PFvAvUXbAjzuilwO0wnZ1BCN2QZV/WxKP/ZVpoD7WvC1ZN3XdaglXIM69gLgene9D4UBPube++Mtog8hZlCDnIH67gbgjSjUCLDQff9W9/2XgZ+icSZWatBMy63Ada5APWgE2Yws7VeR2XAFEqHzkTV5PvASmtDqibugBfAVuxA933yTDWAIeA55CscTK1kudchibUNl3o3CUA+gwSVppiLhvoGo5w+5svwIPfs9aHA+QKSsb0H/SxMlN3yM+9Or3evyAp+xee/XoD6zGvgkivCdKG2xJkz2GJdf/lJSGQJu0JDbiBrhh5BwtwJXI7N2FprA8kKeIbIYrPv8pWjYriVWAW8BFgOXAR9HOlOP3L0DaIJjqvu3fBE9H3e/9wlgPzFaFovQ3pEfdYU5jXrCd5A1tgdZZFuQJ3Mu6virgeVINLeQvIDXowHkI8hrWIDaQT79aOLtocRKNpyVwNtQu8ug0NN9pKc2jajBHUWNcAA9528BP0T9aBCJ+hAwF/0P81GYagB5ZyX0HpYC70dC3MRwQRpE/WAa6i8HXLGmIJvjc8DfoaZbLtMzC5Hj7/Fj5IuUXnbKX8AbiYbbmagDX4oaYgPqwKfQ058ywt/pR67hCWL3t96FjNY3oKhDM+q/57hXAxpjCnEM9aPYEj4mod7QDlzrCmdRp2xB7nU7EubjqPUdRi7Bb5CQL0WW2XxkVR6Ko6B51CCvqh2NcKvRs2+i+GqGART7ToulaA5hEmp7LwCvpFiew8DTaFLXz23sQYPcIXIVcDaq57Wojo37/G/QAFACvENwHVGE5jSqoh3IEdiHxozJ7ndOAutQE25E/ex9KEHm4dIUa9xkUPf4AOpanpNoEHqS0me1lreA+1S2NyNLcQGFZ8qb3dcDRGZttg/TjxrdBvcek4B7R2G1K/IFeUU47n5+Cj3UlqyfW/f7e9D81gliEHAfk21HceMrUKc9inrJMWTdznWF7Ue9ZDcSn04UOjmNPJ65KD6ahIDXohHxHa7cV4zyef+/TkGeRBqch7xCixTpFRSWSgvvUR1G4nwcxeOfKfDZBaiOVyFrY9D9/oOUbIJmDrKilyHxO4OqZz2KbW9FzmA/EqqMe78TCX4DsnZvQH0qbQGvR8lG70Y2Jqjs3USJXKWmvAU8g57UKmQJHqewlX0MPf1B9FR9jqtnLxLvO9GTHoqnuM2ozb8JhT2zeQmFGa9CjfI4siQ8frz5LfA/xLT+pBZ5M19BvWbI3exBFCvucJ9bgIKRS5B5swK1zD8lCk21oB44HYlTnPjsh/ehkFl+5RaiDsXHQSmFaWDdaxBZrmllnmRzDM0NPDfK596GlLHJfX/I/c7PKZll8R7UtX1XfQVNvXy8yC1aUTOcQm73XozGybSZBnwedTHv2O5DC3j+N6Z7lreAD6Ia+FskFG8C3osE5iRy859AbqG3Aj+GZgRnEanifqLOE5N4L3DFW4ciC3Vo9N2GPNYOZOz82BW9jVwB70Ph54dcUWOhCXkyrWgUeRS4B9VPdmbOfmQCbQYeQYPiCfcP7EGLZOajdLQzyGSKk3YkxtegXjKIKvEbyJL0uevZqwdBrbuWdPBpB9NSuv9YaUJWxzT0TBcjs3gxUWrUYeR9PU5JxLsB2Q83ILEDPbIHUP8odosWFJJvJMpjMCi2vHfixSoJ+Qk6B1GX6Y7pfuUt4BaZop2oQxx37/ORGPeiwNJW5N41ALcRxSP87+9CShqTeIOiCZegvuBDykeQ4ZUvyvXIsfAMIR3sRA0xlqSJJlfI5Wi06AJ+7W6aHyfuI4qHForZ+jDWHCRScdKEQhFXoUE5gwaTXchdaaDAOVCOyWiwqifZPPCMu+90IlPsAOlb3/n4FMc1qKxtaHL7QiJPyyID6QlKlhpVg7KyziUKI54EXqa4M1fririM4fNHB0gmijcSU1H1ZafJ+0SoXuLb0aG8BTybPtSAijWiOmQxXEzk9oGsyQ3Eno2whCjuZZAIv4jSAvNDsNOQlnoGiByK2LbumItchHY0qvwWLek+W2ajkSop5qHJwGWo5w+i3voY8hAuZfgqS28GzUYTEa3IFEoq99qvBm1z9+5DXsvBhO4/VuYhb/UzSCELzS8NAv+KDKWCZ8KMj2xLdQg52oconl05BTkFa8gVcD82Hi5d0c4agyZjVyFbox6V6wyKOMU5b105Aj4aK1GMtJ0oN3wA+BTqPDFOHtWiMSN73OhE+dz5W17MQpOca9z3p9GY9GNkEMdmpK1AMewalF737Dj/jp8kjps6NEP1VeRnz3LX/x4txXsZhX0eQMJ4KzLpZhCNjm1oJPUbXCUl4HVowrUJPeBeNDqXkwU+E2WYvJviKVHdqH43UNJ00Vqi1FrQY/k2SpEvluByOwq5nEPJ1xFNCIOE+1ZUlX6B3kGi3SfiHLdfHwI+H3WY5USry06iBrgLxTJiCp9krzhfgsaNQyhk8gy54l0DvBPND/kkCr/v0mOuyLF5+ee4gvYgP3W8e3Fk955twPMTLFexe0xGC0gWIwH2rvwW5NocQc90P+olA+7zlxMJeFo9vQ5l+TSjScPn0cMtl+WCBoW/zkcmY7F66kcDn89IKhH9qH8cR4+tBo3RnSjhKdtjrUGOwkWuqOW4//UiImfLl+954N+QeMe5ZrCyBdwv47oMddyL3PUh1Aq2oQYYcy5wE+oPXjdeRCHm7VmfqUEaeiOKBsxDxd+BJjgLZXKVFJ+D1YMGtf3j+BvZO9T1oxDGlpKULpcGFP5YhSzFGvQcH0aVm50KetS9driytaKtAUCi+RrJxr99LunlqGH41a2niXUO5qzwVkczKusg8g78Ip4WcpcSQ0nr7wxRNuMZV4S3IkNmH7kTfrVoLDwfxcDLDR8tm46qyifLdQL/kdD9K5dmFNf9EvLJfAzjBGoh30TmcIyus0V6+CtUmTehVKJnyI3azEBRjFVECRMGZajEncSRU9jTyCocjzvfgixjg0anR4lnV7qVKOvkFnevrciV/wJnNxhvQnGp2NJ6CtCIevNcZFwcRCGItPZjKcQQyterR433wyjP7SXUd76GGvNMZHHci0zKI6W5/YC77XYU9VqCnOhbUXgxO3GoFnXxcrS861EV3YS8Az8Ofovktk2vXAGvRWbsraizNBJZhx0oJvE0se954nkcuX+/JMrzzqaR3HVIh9EJ0DtIb53JmPGrXv8c7Rs9BfW+w5R2WbhBvXUtWp7nRzm/jG0kEcygUbIVDVS70ezReDyNiXARipG1ot7le3U5shnV0YMoTt+HjCLvKdShOm2meJx8AnwDWd23oMd+HhL07IhO9lYTx1xxL8y6Zoj2rUuSc1051riv64kWez9Mcrvtjirgxpj56HyTc9Gjvdta+3VjzDTgP5Ht+zLwQWttcpPBjcjNXo6sQr/j4AE0K7iZRFe97XW363Lv2ePGVKIwva/w48hq7yXd1d5johH5ideiXnYCDY6lPlWmBvnLl6HAIig80o1aWDE33s+KLUGxrH7kgW1zv5ck89AERz0amXvRIJJU+KTB3bsB9YWR7vuqe/l5jAy5aaED6H84RSwexBZ3yzY01TGF3EQAf4bIKeRI96C0vEXkCleG2Ha4LYrfZfdaVGaf3fo0WrQ8mvT4KNZJ1FzHG6Eai2cyAHzGWtuOVoh/0hhzCVqH8pC1dglK0ls3wt8oPdOQmLQj68CiJ/4QGlYSXld7CulZN8NDrkuRa3gLUYrRa2hfo1cpn9BoQfwGD+9Hcd0Mig99HVm5pb7XjeSaWF1IiHdRuJX71bo3o6V9b0CV+yOU2vNoics4GucT7YfahTyHDSQ3gTkXpVauItcrHSvZnz+CXMsuYku03oYOPthMlOnpE8h6UfRsN/ALFFP+GbmT/f6zSUeopiKPeiWRc3IUhUR7x/D7k9DEbSsTG3xGtcCttd24eQVr7TFjTBcaNNeiZgLwXZRZ/NkJlGVsGGTl3E60VBoU51wP3EX6+1TnsQZFBBrc910oBJk4NcjCWoiyUEZLDWtCaZhrkHhPQaL4z6iVllKUpiPxfSManE8h//qzqMIK+XZLkbW7Ap0S04wE54tokEl6y9apRIckgIS7I6F716NB7ENoLUQdWsG8Cfg9ytMbiQa0z8wtJGrO9iPhvg3ZYhehdVndqOjrkdjsQyEU6z7fRNSfTpD80adtTGz5vvc8XmFiOexnFQM3xixEXWYDMNuJO9babmPMrCK/cwdwxwTKOJwGFJM4j+iJbkJZ84VM4BTIoMjODcht8dla29C82iNpFMrvYXIJqqdiAp5B1tsyFNK4APWQjejJv0RpxXsK6r0fJDoW7Rgyv3wL925KK8oJb0fhswtd+VpQhkonis/73p4kra4cfve+w5Rs575R8Rk4c5DH1Ef0DP1WfyPRg8zJK91nj6NB/nFij/ENudsPoajPXlRtu1EzPeFeA0SR0uxHa0nuUWdQc1uJ7A3PIBqM8stWjAEUDpro3npjFnBjzGRkf33aWvuaMWPzzay1dyPPAmPMxOq5huisotnu3RJtVvULysbyrkf96E70oKegB7wejTOPJV0gv8fzVDQEd7vC5MdvJiFL9lw0YXkxsii3opiP39GxlLSgSrqZyKw6g+LXfiT0XIBi5DcisWkh2mx9M7K8D5POAD4TeQ/+4IOjaCBJAp/y5ydO/YEMs1HQ+I2MXCdPIitjsfv+EBoIf0Vi5u0B98rftS+7uWUYHhWqJblsjFrk8F2LmqFF/foEqrJTjF3Any5Becb0fxtjapF4/8Ba+xN3uccYM8dZ33MYW+hnYsxBVtddqLF5fIy0jGb75yJXcAWq5D4U776P3PzwxDiIZlcuQnnSp1Gu0yvkivgV7ufvQQtj9qJ9MH6I0mbi2Od2EhJuv9OkcV/fiMIk2YPyVSj42EC0380xdNjgr5FZk1DmUQ4GeQWziLZe3Uw6D3s/SjvYhcJfa5DHOhJ+YYLnUZRSlWQK5ig0IAloIDfK8ybkFMaNn275MBoT/YLvPyCD7A8o6pek7TCWLBSDFhV1WWu/lvWj+1Ho6svufTw7a4ydOmR93YQ68DmokzyNZjfiWFAyTupQX76OaJP67cB/IeviSBqF2oHSxVYhC7ENmRB7kYA3oa1ab0PZHLNQa/wpCp1sY+zmxdlisl6eevS855A7wEwjEu9dSGA6kYDvJzmLtxDXoZCOZyqqxyFUrj6SmW2bhU4V2IIMHV9/IznNGaJEgEeQm/hkjGUcB2eIVjZm/0vN5GavxIWPLC4lyrbsQ/kSfv/ypB2/sVjgV6Ns605jTIe79jkk3PcZY25HdtwHYikhSAUXo4m05cg6s8hVfoJoCrtMWIQSAS4j2hfhOWTwJrmnUg77UXihF4niDFSfu1ErbEGTWFehEagHtcyHkRAkLYx+R7/WvOun0XM/iAbvThJayjoKBg18M9zXk1D9TkY9vRPNxMUVE/cbT1mkZkuRidjA6L3cEp371YsG+g7KZ49Why9ifpy5jmR2DfaPdYa7nz8LZTPKxDyQQBnyGUsWyu8pPna/vbTFKYBfmvxnKPDU7q77LUXvJfbVlmfLbahi/KZ9TyEdjP2g4pE4gERkI7LC56LNv95MZIFf5T63HvlT95Jc+ttYZ6L2ogHlRyi74lXK50TbeqJT25tRqM8gk/FvUEgizknNPiJ1M8gbKNRzC9XzKWRlPIZW2JTLvi0FKDSBmYTlm30fiwaTnciGTG4BTC7lvRIzg4TmCyiR2ue5vIaCOr9CQ1+ZrIRpRB7rtURzQaDoxQuplCiP19AJsKeRWF+I8pZx1zYhv6oLCXlSnfgQCiB+EaXttBLt1N9BrkCvd9f9jFG5CI1F6w9Wo6BsI9Ep7y+h9Qn7Yrx/HwolHkeu30JUl41Fyvo8qlufy78eGUS7KZ86LUIPmi/2/9okZH9MR80iLjHPjvLtQ8L9VWLav3+MlLeAtyIlXIn8lnqieOLzqIOUiXg3oT7zATRf5A+xWY908eW0CpbNINHGLadQJv8sVLjn0CSgD7MkWa8nURDuYWRR+zS8Xle27ElML97lJjIWWa9+75M6ouW5B5CQx5mX7rNenkLqMhNZDYViCxaF1F4mWjK4k2jnwTJmCE3L9KDEmnYUYa2l8FhVSgbR/NU3UFXvRMZZms5/eQv4bPSELnbf9yPh2YOEKK5zisbBTJTA8QkUTh5AOvM95OknvSVHQSwaVX6OOu5iZK2tR+L9EyQySS8N7UPPshuZNZXK4+6VJl3uBQqBvc6wyPnei5zGi4nmhuMWswE0Pv9VzPc5G8pbwBcjdxRkkW0C/p3opIQy4mq017c/AvEE8kbvI52sthE5gVz6R4lOuRmi/KzaQKAA3oZ7Djk330POW7HdFl7PlLeAb0Pm7Efc9z797QRlp4o1RLmpPSgD73eU1dxqLv4gzkCgAnkBRXt2oqhaD9Un3lDuAr4X5ehsdN+/guLffsebMuIgakwbkeXdgSITZVbMQOB1wSH36hrtg69zjLXJScyEl9IHAoFAdbLJWrs8/2I5HnQRCAQCgTEQBDwQCAQqlCDggUAgUKEkPYl5EOWQlNHOJWXBDEKd5BPqZDihToZTLXVyXqGLiU5iAhhjnioUjK9mQp0MJ9TJcEKdDKfa6ySEUAKBQKBCCQIeCAQCFUoaAn53Cvcsd0KdDCfUyXBCnQynqusk8Rh4IBAIBEpDCKEEAoFAhRIEPBAIBCqUxATcGHO9MWa7MWanMWZdUvctN4wxLxtjOo0xHcaYp9y1acaYB40xO9x7/kmQrzuMMfcYY3qNMVuyrhWtB2PMX7u2s90YsyadUsdLkTq5yxiz17WXDmPMO7N+Vg11Mt8Y84gxpssYs9UY8xfuelW3lf/HWhv7C+20+gI6wKsOnftySRL3LrcXOgdlRt61fwTWua/XAf+QdjkTqIdrgGXAltHqAR0v+gw6k2mRa0uZtP+HhOrkLuAvC3y2WupkDrDMfd2MzuK6pNrbin8lZYGvAHZaa1+01p5BZ4WsTejelcBa4Lvu6+8CN6VXlGSw1j6GdgTNplg9rAXutdb2WWtfQjv3rkiinElSpE6KUS110m2tfdp9fQztINtGlbcVT1IC3kZ0fCroQI22hO5dbljg18aYTcaYO9y12dbablCDJTq+udooVg/V3n4+ZYx51oVYfKig6urEGLMQnVy4gdBWgOQE3BS4Vq35i1dba5ehM8M/aYy5Ju0CVQDV3H6+hQ4XvBydGvpVd72q6sQYMxn4MfBpa+1IBypWVb0kJeB70GHtnnno7Oyqw1q7z733Av+N3LseY8wcAPfem14JU6VYPVRt+7HW9lhrB621Q8C3icIBVVMnxphaJN4/sNb+xF0ObYXkBHwjsMQYs8gYUwfcDNyf0L3LBmNMkzGm2X8NXAdsQXVxm/vYbcDP0ilh6hSrh/uBm40x9caYRcAS4MkUypc4XqQc70XtBaqkTowxBh1E32Wt/VrWj0JbgWSyUNzs8DvRDPILwOfTnr1N44WycJ5xr62+HoDp6Jz4He59WtplTaAufohCAv3Iarp9pHoAPu/aznbghrTLn2CdfB/oROdk3w/MqbI6eSsKgTyLjprtcFpS1W3Fv8JS+kAgEKhQwkrMQCAQqFCCgAcCgUCFEgQ8EAgEKpQg4IFAIFChBAEPBAKBCiUIeCAQCFQoQcADgUCgQvk/h1R4nZEKwIsAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images=[train_m_ds[i][0] for i in range(8)]\n",
    "show_labels=[train_m_ds[i][1] for i in range(8)]\n",
    "show_img_grid=make_grid(show_images)\n",
    "matplotlib_imshow(show_img_grid,one_channel=False)\n",
    "writer.add_image(\"mnist_m_images\",show_img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Source-Only Training\n",
    "\n",
    "在源域上独立训练CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(CNN,self).__init__()\n",
    "        self.features=nn.Sequential(\n",
    "            nn.Conv2d(3,32,5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,48,5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((5,5))\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(48*5*5,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=x.expand(x.data.shape[0],3,image_size,image_size)\n",
    "        x=self.features(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "用一个5层的神经网络在mnist上使用Adam训练，准确率约为73%(考虑到理想的最高正确率为75%，这里CNN的表现已经足够)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/625 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94ed53b4fb6648ad8fa85b565b3776df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2688x28 and 2352x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images,labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# images=images.cuda()\u001B[39;00m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# labels=labels.cuda()\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 24\u001B[0m     predict\u001B[38;5;241m=\u001B[39m\u001B[43mcnn_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m     losses\u001B[38;5;241m=\u001B[39mLoss(predict,labels)\n\u001B[1;32m     26\u001B[0m     train_loss\u001B[38;5;241m.\u001B[39mupdate(losses\u001B[38;5;241m.\u001B[39mdata,images\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mAutoEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 29\u001B[0m     encoded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     decoded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(encoded)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoded\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (2688x28 and 2352x128)"
     ]
    }
   ],
   "source": [
    "cnn_model=CNN()\n",
    "optimizer=Adam(cnn_model.parameters(),lr=0.001)\n",
    "Loss=nn.CrossEntropyLoss()\n",
    "epochs=5\n",
    "train_loss=AverageMeter()\n",
    "test_loss=AverageMeter()\n",
    "test_top1=AverageMeter()\n",
    "train_top1=AverageMeter()\n",
    "train_cnt=AverageMeter()\n",
    "print_freq=100\n",
    "# cnn_model.cuda()\n",
    "for epoch in range(epochs):\n",
    "    lr=adjust_learning_rate(optimizer,epoch)\n",
    "    writer.add_scalar(\"lr\",lr,epoch)\n",
    "    train_loss.reset()\n",
    "    train_top1.reset()\n",
    "    train_cnt.reset()\n",
    "    test_top1.reset()\n",
    "    test_loss.reset()\n",
    "    for images,labels in tqdm(train_dl):\n",
    "        # images=images.cuda()\n",
    "        # labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predict=cnn_model(images)\n",
    "        losses=Loss(predict,labels)\n",
    "        train_loss.update(losses.data,images.size(0))\n",
    "        top1=accuracy(predict.data,labels,topk=(1,))[0]\n",
    "        train_top1.update(top1,images.size(0))\n",
    "        train_cnt.update(images.size(0),1)\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        if train_cnt.count%print_freq==0:\n",
    "            print(\"Epoch:{}[{}/{}],Loss:[{:.3f},{:.3f}],prec[{:.4f},{:.4f}]\".format(epoch,train_cnt.count,len(train_dl),train_loss.val,train_loss.avg,\n",
    "                                                            train_top1.val,train_top1.avg))\n",
    "    for images,labels in tqdm(test_dl):\n",
    "        # images=images.cuda()\n",
    "        # labels=labels.cuda()\n",
    "        predict=cnn_model(images)\n",
    "        losses=Loss(predict,labels)\n",
    "        test_loss.update(losses.data,images.size(0))\n",
    "        top1=accuracy(predict.data,labels,topk=(1,))[0]\n",
    "        test_top1.update(top1,images.size(0))\n",
    "    print(\"Epoch:{},val,Loss:[{:.3f}],prec[{:.4f}]\".format(epoch,test_loss.avg,test_top1.avg))\n",
    "    writer.add_scalar(\"train_loss\",train_loss.avg,epoch)\n",
    "    writer.add_scalar(\"test_loss\",test_loss.avg,epoch)\n",
    "    writer.add_scalar(\"train_top1\",train_top1.avg,epoch)\n",
    "    writer.add_scalar(\"test_top1\",test_top1.avg,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Direct Transferring\n",
    "\n",
    "直接用mnist数据集训练的网络识别ColoredMNIST数据集，准确率约为72.3%.可以看作领域适应方法准确率的上界。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_m_top1=AverageMeter()\n",
    "test_m_loss=AverageMeter()\n",
    "for images,labels in tqdm(test_m_dl):\n",
    "    # images=images.cuda()\n",
    "    # labels=labels.cuda()\n",
    "    predict=cnn_model(images)\n",
    "    losses=Loss(predict,labels)\n",
    "    test_m_loss.update(losses.data,images.size(0))\n",
    "    top1=accuracy(predict.data,labels,topk=(1,))[0]\n",
    "    test_m_top1.update(top1,images.size(0))\n",
    "print(\"Epoch:{},val,Loss:[{:.3f}],prec[{:.4f}]\".format(epoch,test_m_loss.avg,test_m_top1.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Direct Training\n",
    "\n",
    "直接使用ColoredMNIST训练，准确率约为30.3050%，可以看坐领域适应方法准确率的下界。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss=AverageMeter()\n",
    "test_loss=AverageMeter()\n",
    "test_top1=AverageMeter()\n",
    "train_top1=AverageMeter()\n",
    "train_cnt=AverageMeter()\n",
    "print_freq=200\n",
    "# cnn_model.cuda()\n",
    "epochs=5\n",
    "for epoch in range(epochs):\n",
    "    lr=adjust_learning_rate(optimizer,epoch)\n",
    "    writer.add_scalar(\"lr\",lr,epoch)\n",
    "    train_loss.reset()\n",
    "    train_top1.reset()\n",
    "    train_cnt.reset()\n",
    "    test_top1.reset()\n",
    "    test_loss.reset()\n",
    "    for images,labels in tqdm(train_m_dl):\n",
    "        # images=images.cuda()\n",
    "        # labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predict=cnn_model(images)\n",
    "        losses=Loss(predict,labels)\n",
    "        train_loss.update(losses.data,images.size(0))\n",
    "        top1=accuracy(predict.data,labels,topk=(1,))[0]\n",
    "        train_top1.update(top1,images.size(0))\n",
    "        train_cnt.update(images.size(0),1)\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        if train_cnt.count%print_freq==0:\n",
    "            print(\"Epoch:{}[{}/{}],Loss:[{:.3f},{:.3f}],prec[{:.4f},{:.4f}]\".format(epoch,train_cnt.count,len(train_dl),train_loss.val,train_loss.avg,\n",
    "                                                                   train_top1.val,train_top1.avg))\n",
    "    for images,labels in tqdm(test_m_dl):\n",
    "        # images=images.cuda()\n",
    "        # labels=labels.cuda()\n",
    "        predict=cnn_model(images)\n",
    "        losses=Loss(predict,labels)\n",
    "        test_loss.update(losses.data,images.size(0))\n",
    "        top1=accuracy(predict.data,labels,topk=(1,))[0]\n",
    "        test_top1.update(top1,images.size(0))\n",
    "    print(\"Epoch:{},val,Loss:[{:.3f}],prec[{:.4f}]\".format(epoch,test_loss.avg,test_top1.avg))\n",
    "    writer.add_scalar(\"train_loss\",train_loss.avg,epoch)\n",
    "    writer.add_scalar(\"test_loss\",test_loss.avg,epoch)    \n",
    "    writer.add_scalar(\"train_top1\",train_top1.avg,epoch)\n",
    "    writer.add_scalar(\"test_top1\",test_top1.avg,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gradient Reverse Layer (GRL)\n",
    "\n",
    "梯度反转层，这一层正向表现为恒等变换，反向传播是改变梯度的符号，alpha用来平衡域损失的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class GRL(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DANN(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(DANN,self).__init__()\n",
    "        self.features=nn.Sequential(\n",
    "            nn.Conv2d(3,32,5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,48,5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((5,5))\n",
    "        self.task_classifier=nn.Sequential(\n",
    "            nn.Linear(48*5*5,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,num_classes)\n",
    "        )\n",
    "        self.domain_classifier=nn.Sequential(\n",
    "            nn.Linear(48*5*5,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,2)\n",
    "        )\n",
    "        self.GRL=GRL()\n",
    "    def forward(self,x,alpha):\n",
    "        x = x.expand(x.data.shape[0], 3, image_size,image_size)\n",
    "        x=self.features(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        task_predict=self.task_classifier(x)\n",
    "        x=GRL.apply(x,alpha)\n",
    "        domain_predict=self.domain_classifier(x)\n",
    "        return task_predict,domain_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Domain Transfer Training\n",
    "\n",
    "使用DANN进行领域迁移训练，使用mnist上的有标签数据和ColoredMNIST上的无标签数据，准确率约为50.41%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss=AverageMeter()\n",
    "train_domain_loss=AverageMeter()\n",
    "train_task_loss=AverageMeter()\n",
    "test_loss=AverageMeter()\n",
    "test_top1=AverageMeter()\n",
    "test_domain_acc=AverageMeter()\n",
    "train_top1=AverageMeter()\n",
    "train_cnt=AverageMeter()\n",
    "\n",
    "print_freq=200\n",
    "domain_model=DANN()\n",
    "# domain_model.cuda()\n",
    "domain_loss=nn.CrossEntropyLoss()\n",
    "task_loss=nn.CrossEntropyLoss()\n",
    "lr=0.001\n",
    "optimizer=Adam(domain_model.parameters(),lr=lr)\n",
    "epochs=100\n",
    "states=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #lr=adjust_learning_rate(optimizer,epoch)\n",
    "    writer.add_scalar(\"lr\",lr,epoch)\n",
    "    train_loss.reset()\n",
    "    train_domain_loss.reset()\n",
    "    train_task_loss.reset()\n",
    "    train_top1.reset()\n",
    "    train_cnt.reset()\n",
    "    test_top1.reset()\n",
    "    test_loss.reset()\n",
    "    for source,target in zip(train_dl,train_m_dl):\n",
    "        train_cnt.update(images.size(0),1)\n",
    "        p = float(train_cnt.count + epoch * len(train_dl)) / (epochs *len(train_dl))\n",
    "        alpha = torch.tensor(2. / (1. + np.exp(-10 * p)) - 1)\n",
    "        src_imgs=source[0]\n",
    "        src_labels=source[1]\n",
    "        dst_imgs=target[0]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src_predict,src_domains=domain_model(src_imgs,alpha)\n",
    "        src_label_loss=task_loss(src_predict,src_labels)\n",
    "        src_domain_loss=domain_loss(src_domains,torch.ones(len(src_domains)).long())\n",
    "        \n",
    "        _,dst_domains=domain_model(dst_imgs,alpha)\n",
    "        dst_domain_loss=domain_loss(dst_domains,torch.zeros(len(dst_domains)).long())\n",
    "        \n",
    "        losses=src_label_loss+src_domain_loss+dst_domain_loss\n",
    "        \n",
    "        train_loss.update(losses.data,images.size(0))\n",
    "        train_domain_loss.update(dst_domain_loss.data,images.size(0))\n",
    "        train_task_loss.update(src_label_loss.data,images.size(0))\n",
    "        top1=accuracy(src_predict.data,src_labels,topk=(1,))[0]\n",
    "        train_top1.update(top1,images.size(0))\n",
    "        \n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        if train_cnt.count%print_freq==0:\n",
    "            print(\"Epoch:{}[{}/{}],Loss:[{:.3f},{:.3f}],domain loss:[{:.3f},{:.3f}],label loss:[{:.3f},{:.3f}],prec[{:.4f},{:.4f}],alpha:{}\".format(\n",
    "                epoch,train_cnt.count,len(train_dl),train_loss.val,train_loss.avg,\n",
    "                train_domain_loss.val,train_domain_loss.avg,\n",
    "                train_task_loss.val,train_task_loss.avg,train_top1.val,train_top1.avg,alpha))\n",
    "    for images,labels in tqdm(test_m_dl):\n",
    "        # images=images.cuda()\n",
    "        # labels=labels.cuda()\n",
    "        predicts,domains=domain_model(images,0)\n",
    "        losses=task_loss(predicts,labels)\n",
    "        test_loss.update(losses.data,images.size(0))\n",
    "        top1=accuracy(predicts.data,labels,topk=(1,))[0]\n",
    "        domain_acc=accuracy(domains.data,torch.zeros(len(domains)).long(),topk=(1,))[0]\n",
    "        test_top1.update(top1,images.size(0))\n",
    "        test_domain_acc.update(domain_acc,images.size(0))\n",
    "    print(\"Epoch:{},val,Loss:[{:.3f}],prec[{:.4f}],domain_acc[{:.4f}]\".format(epoch,test_loss.avg,test_top1.avg,test_domain_acc.avg))\n",
    "    states.append([test_loss.avg.item(), test_top1.avg.item(),test_domain_acc.avg.item()])\n",
    "    writer.add_scalar(\"train_loss\",train_loss.avg,epoch)\n",
    "    writer.add_scalar(\"test_loss\",test_loss.avg,epoch)    \n",
    "    writer.add_scalar(\"train_top1\",train_top1.avg,epoch)\n",
    "    writer.add_scalar(\"test_top1\",test_top1.avg,epoch)\n",
    "    writer.add_scalar(\"test_domain\",test_domain_acc.avg,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning States Plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "steps = np.linspace(0, 100, 100)\n",
    "states = np.array(states)\n",
    "\n",
    "plt.figure()\n",
    "# plt.plot(steps, states[:, 0], c='blue', label='Loss')\n",
    "plt.plot(steps, states[:, 1], label='Precision')\n",
    "plt.plot(steps, states[:,2], label='Domain Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('DANN2 Performance on ColoredMNIST')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(steps, states[:, 0],  label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('DANN Loss Performance on ColoredMNIST')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}